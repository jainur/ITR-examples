{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05bd67-bd1f-4126-97c4-30f855181fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import osc_ingest_trino as osc\n",
    "import trino\n",
    "from sqlalchemy.engine import create_engine\n",
    "\n",
    "import ITR\n",
    "\n",
    "from ITR.configs import ITR_median, ITR_mean\n",
    "from ITR.data.data_warehouse import DataWarehouse\n",
    "from ITR.portfolio_aggregation import PortfolioAggregationMethod\n",
    "from ITR.temperature_score import TemperatureScore\n",
    "\n",
    "from ITR.data.base_providers import BaseProviderProductionBenchmark, BaseProviderIntensityBenchmark\n",
    "from ITR.data.template import TemplateProviderCompany\n",
    "from ITR.data.vault_providers import dequantify_df\n",
    "from ITR.interfaces import EScope, ETimeFrames, EScoreResultType, IEIBenchmarkScopes, IProductionBenchmarkScopes, ProjectionControls\n",
    "# from ITR.configs import LoggingConfig\n",
    "\n",
    "from ITR.data.osc_units import ureg, Q_, PA_, asPintSeries\n",
    "from pint import Quantity\n",
    "from pint_pandas import PintArray, PintType\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56fd6e-16fe-47b2-b77e-6804aa831148",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') # LoggingConfig.FORMAT\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "logger.info(\"Start!\")\n",
    "\n",
    "examples_dir ='' #'examples'\n",
    "data_dir=\"data\"\n",
    "data_json_units_dir=\"json-units\"\n",
    "root = os.path.abspath('')\n",
    "\n",
    "company_data_path = os.path.join(root, examples_dir, data_dir, \"20230106 ITR V2 Sample Data.xlsx\")\n",
    "\n",
    "# Production benchmark (there's only one, and we have to stretch it from OECM to cover TPI)\n",
    "benchmark_prod_json_file = \"benchmark_production_OECM.json\"\n",
    "benchmark_prod_json = os.path.join(root, examples_dir, data_dir, data_json_units_dir, benchmark_prod_json_file)\n",
    "with open(benchmark_prod_json) as json_file:\n",
    "    parsed_json = json.load(json_file)\n",
    "\n",
    "oil_prod_bm = [bm for bm in parsed_json['AnyScope']['benchmarks'] if bm['sector']=='Oil'][0]\n",
    "oil_base_prod = ureg(oil_prod_bm['base_year_production']).to('MJ')\n",
    "oil_prod_series = pd.DataFrame({**{'year': [oil_prod['year'] for oil_prod in oil_prod_bm['projections_nounits']]},\n",
    "                                **{'value': [oil_prod['value'] for oil_prod in oil_prod_bm['projections_nounits']]}}).set_index('year').squeeze()\n",
    "oil_prod_series = oil_prod_series.add(1).cumprod().mul(oil_base_prod.m)\n",
    "\n",
    "gas_prod_bm = [bm for bm in parsed_json['AnyScope']['benchmarks'] if bm['sector']=='Gas'][0]\n",
    "gas_base_prod = ureg(gas_prod_bm['base_year_production']).to('MJ')\n",
    "gas_prod_series = pd.DataFrame({**{'year': [gas_prod['year'] for gas_prod in gas_prod_bm['projections_nounits']]},\n",
    "                                **{'value': [gas_prod['value'] for gas_prod in gas_prod_bm['projections_nounits']]}}).set_index('year').squeeze()\n",
    "gas_prod_series = gas_prod_series.add(1).cumprod().mul(gas_base_prod.m)\n",
    "\n",
    "oil_and_gas_prod_series = oil_prod_series.add(gas_prod_series).div(oil_base_prod.m + gas_base_prod.m)\n",
    "oil_and_gas_prod_series = oil_and_gas_prod_series.div(oil_and_gas_prod_series.shift(1))\n",
    "oil_and_gas_prod_series.iloc[0] = 1.0\n",
    "oil_and_gas_prod_series = oil_and_gas_prod_series.sub(1)\n",
    "\n",
    "oil_and_gas_bm = dict(oil_prod_bm)\n",
    "oil_and_gas_bm['sector'] = 'Oil & Gas'\n",
    "oil_and_gas_bm['base_year_production'] = f\"{oil_base_prod + gas_base_prod:~P}\"\n",
    "oil_and_gas_bm['projections_nounits'] = [ {'year': year, 'value': value} for year,value in oil_and_gas_prod_series.to_dict().items() ]\n",
    "parsed_json['AnyScope']['benchmarks'].append(oil_and_gas_bm)\n",
    "\n",
    "# coal_prod_bm = dict([bm for bm in parsed_json['AnyScope']['benchmarks'] if bm['sector']=='Coal'][0])\n",
    "# coal_base_prod = ureg(coal_prod_bm['base_year_production']).to('MJ')\n",
    "\n",
    "# coal_prod_bm['sector'] = 'Diversified Mining'\n",
    "# coal_prod_bm['base_year_production'] = f\"{coal_base_prod:~P}\"\n",
    "# parsed_json['AnyScope']['benchmarks'].append(coal_prod_bm)\n",
    "\n",
    "prod_bms = IProductionBenchmarkScopes.parse_obj(parsed_json)\n",
    "base_production_bm = BaseProviderProductionBenchmark(production_benchmarks=prod_bms)\n",
    "logger.info('Load production benchmark from {}'.format(benchmark_prod_json_file))\n",
    "\n",
    "# Emission intensities\n",
    "benchmark_EI_OECM_PC_file = \"benchmark_EI_OECM_PC.json\"\n",
    "benchmark_EI_OECM_S3_file = \"benchmark_EI_OECM_S3.json\"\n",
    "benchmark_EI_OECM_file = \"benchmark_EI_OECM.json\" # Deprecated!\n",
    "benchmark_EI_TPI_15_file = \"benchmark_EI_TPI_1_5_degrees.json\"\n",
    "benchmark_EI_TPI_file = \"benchmark_EI_TPI_2_degrees.json\"\n",
    "benchmark_EI_TPI_below_2_file = \"benchmark_EI_TPI_below_2_degrees.json\"\n",
    "benchmark_EI_TPI_2deg_high_efficiency_file = \"benchmark_EI_TPI_2_degrees_high_efficiency.json\"\n",
    "benchmark_EI_TPI_2deg_shift_improve_file = \"benchmark_EI_TPI_2_degrees_shift_improve.json\"\n",
    "\n",
    "# loading dummy portfolio\n",
    "df_portfolio = pd.read_excel(company_data_path, sheet_name=\"Portfolio\")\n",
    "companies = ITR.utils.dataframe_to_portfolio(df_portfolio)\n",
    "logger.info('Load dummy portfolio from {}. You could upload your own portfolio using the template.'.format(company_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3f3d2-d262-4fe5-83d3-c2c17eb3961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eibm = 'OECM_S3'\n",
    "\n",
    "if eibm == 'OECM_PC':\n",
    "    benchmark_file = benchmark_EI_OECM_PC_file\n",
    "elif eibm == 'OECM_S3':\n",
    "    benchmark_file = benchmark_EI_OECM_S3_file\n",
    "elif eibm.startswith('TPI_2_degrees'):\n",
    "    benchmark_file = benchmark_EI_TPI_file\n",
    "elif eibm == 'TPI_15_degrees':\n",
    "    benchmark_file = benchmark_EI_TPI_15_file\n",
    "elif eibm == 'OECM':\n",
    "    benchmark_file = benchmark_EI_OECM_file\n",
    "    logger.info('OECM benchmark is for backward compatibility only.  Use OECM_PC instead.')\n",
    "else:\n",
    "    benchmark_file = benchmark_EI_TPI_below_2_file\n",
    "# load intensity benchmarks\n",
    "benchmark_EI = os.path.join(root, examples_dir, data_dir, data_json_units_dir, benchmark_file)\n",
    "with open(benchmark_EI) as json_file:\n",
    "    parsed_json = json.load(json_file)\n",
    "if eibm.startswith('TPI_2_degrees'):\n",
    "    extra_EI = os.path.join(root, examples_dir, data_dir, data_json_units_dir,\n",
    "                            benchmark_EI_TPI_2deg_high_efficiency_file if '_high_efficiency' in eibm\n",
    "                            else benchmark_EI_TPI_2deg_shift_improve_file)\n",
    "    with open(extra_EI) as json_file:\n",
    "        extra_json = json.load(json_file)\n",
    "        for scope_name in EScope.get_scopes():\n",
    "            if scope_name in extra_json:\n",
    "                if scope_name not in parsed_json:\n",
    "                    parsed_json[scope_name] = extra_json[scope_name]\n",
    "                else:\n",
    "                    parsed_json[scope_name]['benchmarks'] += extra_json[scope_name]['benchmarks']\n",
    "EI_bm = BaseProviderIntensityBenchmark(EI_benchmarks=IEIBenchmarkScopes.parse_obj(parsed_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3abfd-345c-42e4-a713-c1530eec6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_company_data = TemplateProviderCompany(company_data_path, projection_controls = ProjectionControls())\n",
    "Warehouse = DataWarehouse(template_company_data, benchmark_projected_production=None, benchmarks_projected_ei=None,\n",
    "                          estimate_missing_data=DataWarehouse.estimate_missing_s3_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53ef48-ce1a-432c-906d-2ed8299d8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This updates benchmarks and all that depends on them (including trajectories)\n",
    "Warehouse.update_benchmarks(base_production_bm, EI_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747b7b6-3e9f-4ce7-a110-72ae4a15d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some standard environment variables from a dot-env file, if it exists.\n",
    "# If no such file can be found, does not fail, and so allows these environment vars to\n",
    "# be populated in some other way\n",
    "dotenv_dir = os.environ.get('CREDENTIAL_DOTENV_DIR', os.environ.get('PWD', '/opt/app-root/src'))\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / 'credentials.env'\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path,override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222a343-0846-44bc-9b4e-ba1e4b12b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing Dev tables\")\n",
    "\n",
    "sqlstring = 'trino://{user}@{host}:{port}/'.format(\n",
    "    user = os.environ['TRINO_USER_USER1'],\n",
    "    host = os.environ['TRINO_HOST'],\n",
    "    port = os.environ['TRINO_PORT']\n",
    ")\n",
    "\n",
    "ingest_catalog = 'osc_datacommons_dev'\n",
    "ingest_schema = 'demo_dv'\n",
    "itr_prefix = 'template_'\n",
    "\n",
    "sqlargs = {\n",
    "    'auth': trino.auth.JWTAuthentication(os.environ['TRINO_PASSWD_USER1']),\n",
    "    'http_scheme': 'https',\n",
    "    'catalog': ingest_catalog,\n",
    "    'schema': ingest_schema,\n",
    "}\n",
    "\n",
    "dev_engine = create_engine(sqlstring, connect_args = sqlargs)\n",
    "print(\"connecting with engine \" + str(dev_engine))\n",
    "qres = osc._do_sql(f\"show tables in {ingest_schema}\", dev_engine, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b50a54-3400-4920-bd78-acb4cd1795e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket must be configured with credentials for trino, and accessible to the hive catalog\n",
    "# You may need to use a different prefix here depending on how you name your credentials.env variables\n",
    "hive_bucket = osc.attach_s3_bucket('S3_HIVE')\n",
    "\n",
    "hive_catalog = 'osc_datacommons_hive_ingest'\n",
    "hive_schema = 'ingest'\n",
    "\n",
    "# This will have identity of main notebook user, not OS-Climate-User1\n",
    "ingest_engine = osc.attach_trino_engine(verbose=True, catalog=ingest_catalog, schema=ingest_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cb16d1-92f8-412a-a24e-ebc7c7adf68f",
   "metadata": {},
   "source": [
    "## ITR Company Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce5fe8-9071-4bd9-9cf5-074b7b271306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = template_company_data.df_fundamentals[[\n",
    "    'company_name', 'company_lei', 'company_id',\n",
    "    'sector', 'country', 'region', 'exposure', 'currency',\n",
    "    'report_date',\n",
    "    'company_market_cap', 'company_revenue',\n",
    "    'company_enterprise_value', 'company_ev_plus_cash',\n",
    "    'company_total_assets',\n",
    "    'cash',\n",
    "    'debt' ]].convert_dtypes()\n",
    "\n",
    "df.cash = df.cash.astype(\"Float64\")\n",
    "df.debt = df.debt.astype(\"Float64\")\n",
    "df.rename(columns={'company_enterprise_value':'company_ev', 'company_ev_plus_cash':'company_evic', 'cash':'company_cash_equivalents', 'debt':'company_debt'}, inplace=True)\n",
    "df['year'] = df.report_date.dt.year\n",
    "df.drop(columns='report_date', inplace=True)\n",
    "\n",
    "schema = osc.create_table_schema_pairs(df)\n",
    "\n",
    "company_tablename = f\"{itr_prefix}company_data\"\n",
    "\n",
    "osc._do_sql(f\"drop table if exists {ingest_catalog}.{ingest_schema}.{company_tablename}\", ingest_engine, verbose=True)\n",
    "\n",
    "\n",
    "tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{company_tablename}(\n",
    "{schema}\n",
    ") with (\n",
    "    format = 'ORC',\n",
    "    partitioning = ARRAY['year']\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "osc._do_sql(tabledef, ingest_engine, verbose=True)\n",
    "\n",
    "df.to_sql(company_tablename, ingest_engine, schema=ingest_schema, if_exists=\"append\",\n",
    "          index=False,\n",
    "          method=osc.TrinoBatchInsert(batch_size = 1000, verbose = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f91a4c-1eaa-4a23-b915-4bcb01e599ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_info_at_base_year = template_company_data.get_company_intensity_and_production_at_base_year([company_id for company_id in template_company_data.df_fundamentals.company_id.values if company_id !='US6745991058-chem'])\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # See https://github.com/hgrecco/pint-pandas/issues/128\n",
    "    projected_production = Warehouse.benchmark_projected_production.get_company_projected_production(\n",
    "        company_info_at_base_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c191f183-1df7-4d0f-b8ca-4f65763d0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_tablename = f\"{itr_prefix}production_data\"\n",
    "\n",
    "osc._do_sql(f\"drop table if exists {ingest_catalog}.{ingest_schema}.{production_tablename}\", ingest_engine, verbose=True)\n",
    "\n",
    "\n",
    "production_tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{production_tablename}(\n",
    "    company_name varchar,\n",
    "    company_lei varchar,\n",
    "    company_id varchar,\n",
    "    sector varchar,\n",
    "    year bigint,\n",
    "    production_by_year double,\n",
    "    production_by_year_units varchar) with (\n",
    "    format = 'ORC',\n",
    "    partitioning = ARRAY['year']\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "osc._do_sql(production_tabledef, ingest_engine, verbose=True)\n",
    "\n",
    "# schema = osc.create_table_schema_pairs(production_data)\n",
    "\n",
    "rename_year_columns={ y: f\"y{y}\" for y in range(2000,2100)}\n",
    "df = projected_production.loc[(slice(None), EScope.S1), :].droplevel('scope')\n",
    "df = df.rename(columns=rename_year_columns).reset_index()\n",
    "df2 = pd.wide_to_long(df, stubnames='y', i='company_id', j='year')\n",
    "df2 = df2.rename(columns={'y':'production_by_year'}).reset_index('year')\n",
    "df3 = df2.merge(template_company_data.df_fundamentals[['company_name', 'company_lei', 'sector']], on='company_id')\n",
    "production_df = df3\n",
    "df4 = dequantify_df(df3).reset_index()\n",
    "df4 = df4[['company_name', 'company_lei', 'company_id', 'sector', 'year', 'production_by_year', 'production_by_year_units']]\n",
    "\n",
    "df4.to_sql(production_tablename, ingest_engine, schema=ingest_schema, if_exists=\"append\",\n",
    "           index=False,\n",
    "           method=osc.TrinoBatchInsert(batch_size = 4000, verbose = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c4a32-a174-4a32-9088-c27623965b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tablename = f\"{itr_prefix}target_data\"\n",
    "trajectory_tablename = f\"{itr_prefix}trajectory_data\"\n",
    "\n",
    "osc._do_sql(f\"drop table if exists {ingest_catalog}.{ingest_schema}.{target_tablename}\", ingest_engine, verbose=True)\n",
    "osc._do_sql(f\"drop table if exists {ingest_catalog}.{ingest_schema}.{trajectory_tablename}\", ingest_engine, verbose=True)\n",
    "\n",
    "# schema = osc.create_table_schema_pairs(target_data)\n",
    "\n",
    "ei_schema = ',\\n'.join([f\"ei_{scope.lower()}_by_year double, ei_{scope.lower()}_by_year_units varchar\" for scope in EScope.get_scopes()])\n",
    "\n",
    "target_tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{target_tablename}(\n",
    "    company_name varchar,\n",
    "    company_lei varchar,\n",
    "    company_id varchar,\n",
    "    sector varchar,\n",
    "    year bigint,\n",
    "    {ei_schema}) with (\n",
    "    format = 'ORC',\n",
    "    partitioning = ARRAY['year']\n",
    ")\n",
    "\"\"\"\n",
    "trajectory_tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{trajectory_tablename}(\n",
    "    company_name varchar,\n",
    "    company_lei varchar,\n",
    "    company_id varchar,\n",
    "    sector varchar,\n",
    "    year bigint,\n",
    "    {ei_schema}) with (\n",
    "    format = 'ORC',\n",
    "    partitioning = ARRAY['year']\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "osc._do_sql(target_tabledef, ingest_engine, verbose=True)\n",
    "osc._do_sql(trajectory_tabledef, ingest_engine, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585f762-30cc-440a-8b33-fca74f410df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dfs = []\n",
    "trajectory_dfs = []\n",
    "projection_tablename = [ target_tablename, trajectory_tablename ]\n",
    "\n",
    "for i, projection in enumerate(['projected_targets', 'projected_intensities']):\n",
    "    projection_dfs = []\n",
    "    for company in template_company_data._companies:\n",
    "        ei_dict = {}\n",
    "        for scope in EScope.get_scopes():\n",
    "            if getattr(company, projection)[scope]:\n",
    "                ei_dict[scope] = getattr(company, projection)[scope].projections\n",
    "            else:\n",
    "                ei_dict[scope] = pd.Series(dtype='object')\n",
    "        ei_data = pd.concat([ei_dict[scope] for scope in EScope.get_scopes()], axis=1).reset_index()\n",
    "        ei_data.columns = ['year'] + [f\"ei_{scope.lower()}_by_year\" for scope in EScope.get_scopes()]\n",
    "        df = pd.DataFrame(data=[[company.company_name, '', company.company_id, company.sector] for i in ei_data.index],\n",
    "                          columns=['company_name', 'company_lei', 'company_id', 'sector']).convert_dtypes()\n",
    "        projection_dfs.append(pd.concat([df, ei_data], axis=1))\n",
    "    df2 = pd.concat(projection_dfs).reset_index(drop=True).convert_dtypes()\n",
    "    if projection_tablename[i]==target_tablename:\n",
    "        target_df = df2\n",
    "    df3 = dequantify_df(df2)\n",
    "    df3.to_sql(projection_tablename[i], ingest_engine, schema=ingest_schema,\n",
    "               if_exists=\"append\", index=False,\n",
    "               method=osc.TrinoBatchInsert(batch_size = 4000, verbose = True))\n",
    "\n",
    "osc._do_sql(f\"select count (*) from {target_tablename}\", ingest_engine, verbose=True)\n",
    "osc._do_sql(f\"select count (*) from {trajectory_tablename}\", ingest_engine, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e69b8-3b7f-4ef8-bcb8-ff231b9ee884",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_tablename = f\"{itr_prefix}emissions_data\"\n",
    "\n",
    "osc._do_sql(f\"drop table if exists {ingest_catalog}.{ingest_schema}.{emissions_tablename}\", ingest_engine, verbose=True)\n",
    "\n",
    "# schema = osc.create_table_schema_pairs(target_data)\n",
    "\n",
    "co2_schema = ',\\n'.join([f\"co2_{scope.lower()}_by_year double, co2_{scope.lower()}_by_year_units varchar\" for scope in EScope.get_scopes()])\n",
    "\n",
    "emissions_tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{emissions_tablename}(\n",
    "    company_name varchar,\n",
    "    company_lei varchar,\n",
    "    company_id varchar,\n",
    "    sector varchar,\n",
    "    year bigint,\n",
    "    {co2_schema}) with (\n",
    "    format = 'ORC',\n",
    "    partitioning = ARRAY['year']\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Create emissions_data table using production_df and math\n",
    "emissions_df = production_df.merge(target_df.drop(columns=['company_name', 'company_lei', 'sector']), on=['company_id', 'year'])\n",
    "emissions_df = emissions_df[~emissions_df.company_id.isin(['DE000SYM9999', 'NO0010657505', 'GB0000961622', 'DE000BASF111', 'IE00BZ12WP82', 'FR0004024222'])]\n",
    "print(emissions_df.index.names)\n",
    "for scope in EScope.get_scopes():\n",
    "    mask = emissions_df[f\"ei_{scope.lower()}_by_year\"].isna()\n",
    "    emissions_df.loc[mask, f\"ei_{scope.lower()}_by_year\"] = emissions_df['production_by_year'].map(lambda x: Q_(np.nan, f\"Mt CO2 / ({str(x.u)})\"))\n",
    "    emissions_df[f\"co2_{scope.lower()}_by_year\"] = emissions_df['production_by_year'].mul(emissions_df[f\"ei_{scope.lower()}_by_year\"]).astype(\"pint[Mt CO2e]\")\n",
    "    emissions_df = emissions_df.drop(columns=f\"ei_{scope.lower()}_by_year\")\n",
    "emissions_df = emissions_df.drop(columns='production_by_year')\n",
    "df = dequantify_df(emissions_df)\n",
    "df.to_sql(emissions_tablename, ingest_engine, schema=ingest_schema,\n",
    "          if_exists=\"append\", index=False,\n",
    "          method=osc.TrinoBatchInsert(batch_size = 4000, verbose = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cac00d-f1eb-4b01-af4b-0ac61ce5d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d9edca5-8f88-4f33-8750-4342aec3cd33",
   "metadata": {},
   "source": [
    "osc.fast_pandas_ingest_via_hive(\n",
    "    target_data,\n",
    "    engine,\n",
    "    ingest_catalog, ingest_schema, target_tablename,\n",
    "    hive_bucket, hive_catalog, hive_schema,\n",
    "    partition_columns = ['year'],\n",
    "    overwrite = True,\n",
    "    typemap={\"datetime64[ns]\":\"timestamp(6)\", \"datetime64[ns, UTC]\":\"timestamp(6)\",\n",
    "             # \"Int16\":\"integer\", \"int16\":\"integer\"\n",
    "            },\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f51663c2-a90b-4ec4-abe0-ef5dbbb32dcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "create table if not exists osc_datacommons_dev.demo_dv.itr_company_data(\n",
    "    company_name varchar,\n",
    "    company_lei varchar,\n",
    "    company_id varchar,\n",
    "    sector varchar,\n",
    "    country varchar,\n",
    "    region varchar,\n",
    "    exposure varchar,\n",
    "    currency varchar,\n",
    "    year bigint,\n",
    "    company_market_cap double,\n",
    "    company_revenue double,\n",
    "    company_ev double,\n",
    "    company_evic double,\n",
    "    company_total_assets double,\n",
    "    company_cash_equivalents double,\n",
    "    company_debt double\n",
    ") with (\n",
    "    format = 'ORC',\n",
    "    partitioning = array['year']\n",
    ")\n",
    "\n",
    "create table if not exists osc_datacommons_dev.demo_dv.itr_production_data(\n",
    "    company_name varchar,\n",
    "    company_lei varchar,\n",
    "    company_id varchar,\n",
    "    sector varchar,\n",
    "    year bigint,\n",
    "    production_by_year double,\n",
    "    production_by_year_units varchar\n",
    ") with (\n",
    "    format = 'ORC',\n",
    "    partitioning = array['year']\n",
    ")\n",
    "\n",
    "create table if not exists osc_datacommons_dev.demo_dv.itr_target_data(\n",
    "    company_name varchar,\n",
    "    company_lei varchar,\n",
    "    company_id varchar,\n",
    "    sector varchar,\n",
    "    year bigint,\n",
    "    co2_s1_by_year double,\n",
    "    co2_s1_by_year_units varchar,\n",
    "    co2_s2_by_year double,\n",
    "    co2_s2_by_year_units varchar,\n",
    "    co2_s3_by_year double,\n",
    "    co2_s3_by_year_units varchar,\n",
    "    ei_s1_by_year double,\n",
    "    ei_s1_by_year_units varchar,\n",
    "    ei_s2_by_year double,\n",
    "    ei_s2_by_year_units varchar,\n",
    "    ei_s3_by_year double,\n",
    "    ei_s3_by_year_units varchar\n",
    ") with (\n",
    "    format = 'ORC',\n",
    "    partitioning = array['year']\n",
    ")\n",
    "\n",
    "create table if not exists osc_datacommons_dev.demo_dv.itr_trajectory_data(\n",
    "    company_name varchar,\n",
    "    company_lei varchar,\n",
    "    company_id varchar,\n",
    "    sector varchar,\n",
    "    year bigint,\n",
    "    co2_s1_by_year double,\n",
    "    co2_s1_by_year_units varchar,\n",
    "    co2_s2_by_year double,\n",
    "    co2_s2_by_year_units varchar,\n",
    "    co2_s3_by_year double,\n",
    "    co2_s3_by_year_units varchar,\n",
    "    ei_s1_by_year double,\n",
    "    ei_s1_by_year_units varchar,\n",
    "    ei_s2_by_year double,\n",
    "    ei_s2_by_year_units varchar,\n",
    "    ei_s3_by_year double,\n",
    "    ei_s3_by_year_units varchar\n",
    ") with (\n",
    "    format = 'ORC',\n",
    "    partitioning = array['year']\n",
    ")\n",
    "\n",
    "create table if not exists osc_datacommons_dev.demo_dv.itr_emissions_data(\n",
    "    company_name varchar,\n",
    "    company_lei varchar,\n",
    "    company_id varchar,\n",
    "    sector varchar,\n",
    "    year bigint,\n",
    "    co2_s1_by_year double,\n",
    "    co2_s1_by_year_units varchar,\n",
    "    co2_s2_by_year double,\n",
    "    co2_s2_by_year_units varchar\n",
    ") with (\n",
    "    format = 'ORC',\n",
    "    partitioning = array['year']\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
